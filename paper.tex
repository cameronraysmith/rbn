%------------------------------------------------------------------------------
% Beginning of paper.tex
%------------------------------------------------------------------------------
%
% AMS-LaTeX version 2 sample file for journals, based on amsart.cls.
%
%        ***     DO NOT USE THIS FILE AS A STARTER.      ***
%        ***  USE THE JOURNAL-SPECIFIC *.TEMPLATE FILE.  ***
%
% Replace amsart by the documentclass for the target journal, e.g., tran-l.
%
\documentclass{amsart}

%     If your article includes graphics, uncomment this command.
\usepackage{graphicx}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{xca}[theorem]{Exercise}

\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\numberwithin{equation}{section}

%    Absolute value notation
\newcommand{\abs}[1]{\lvert#1\rvert}

%    Blank box placeholder for figures (to avoid requiring any
%    particular graphics capabilities for printing this document).
\newcommand{\blankbox}[2]{%
  \parbox{\columnwidth}{\centering
%    Set fboxsep to 0 so that the actual size of the box will match the
%    given measurements more closely.
    \setlength{\fboxsep}{0pt}%
    \fbox{\raisebox{0pt}[#2]{\hspace{#1}}}%
  }%
}

% user added
\usepackage{longtable}
\usepackage{dot2texi}
\usepackage{tikz}
\usetikzlibrary{automata,shapes,arrows}
% todo notes see http://www.texample.net/tikz/examples/todo-notes/
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{hyperref}
\hypersetup{colorlinks=true,
linkcolor=[rgb]{.67 .27 .27},
citecolor=[rgb]{.09 .29 .54},
urlcolor=[rgb]{.09 .29 .54}}

% Set autoref text
% http://tex.stackexchange.com/a/36576/6784
\renewcommand*{\figureautorefname}{Fig.}
\renewcommand*{\equationautorefname}{Eq.}
\renewcommand*{\tableautorefname}{Table}
\renewcommand*{\sectionautorefname}{Section}


\def\tr{\mathrm{tr}}
\def\Path{\mathrm{Path}}
\def\hier{\mathrm{Hier}}
\def\Vertex{\mathrm{Vertex}}
\def\adj{\mathrm{adj}}

\begin{document}

% Add Figure, Table prefixes to references
% http://tex.stackexchange.com/a/6063/6784
\let\ref\autoref

\title{Ensemble Stability of Biological Networks}

%    Information for first author
\author{Aviv Bergman}
%    Address of record for the research reported here
\address{Department of Systems and Computational Biology, Albert Einstein College of Medicine, Bronx, New York 10461}
%    Current address
\curraddr{}
\email{aviv@einstein.yu.edu}
%    \thanks will become a 1st page footnote.
% \thanks{The first author was supported in part by NSF Grant \#000000.}

%    Information for second author
\author{Raymond S. Puzio}
\address{Department of Systems and Computational Biology, Albert Einstein College of Medicine, Bronx, New York 10461}
%    Current address
\curraddr{}
\email{rsp@novres.org}
% \thanks{Support information for the second author.}

%    Information for third author
\author{Cameron Smith}
\address{Department of Systems and Computational Biology, Albert Einstein College of Medicine, Bronx, New York 10461}
%    Current address
\curraddr{}
\email{cameron.smith@med.einstein.yu.edu}
% \thanks{Support information for the second author.}

%    General info
% \subjclass[2000]{Primary 54C40, 14E20; Secondary 46E25, 20C20}

% \date{January 1, 2001 and, in revised form, June 22, 2001.}

% \dedicatory{This paper is dedicated to our advisors.}

% \keywords{Differential geometry, algebraic geometry}

\begin{abstract}
The analysis of dynamical systems that attempts to model chemical reaction, gene-regulatory, population, and ecosystem networks all rely on models having many parameters and thus many degrees of freedom. When the details of a system are unknown, one effective approach is to study the dynamical properties of a collection of models determined by constraints applying to all such systems. Here we analyze the stability of a large class of dynamical systems to perturbations in the underlying structure of the system: a property referred to as \emph{structural stability}. In particular, we precisely determine the probability distribution over system connectivity, a parameter which has significant implications from the study of gene-regulatory networks to ecosystem dynamics, of structural stability for systems with two and three interacting components. We show for these cases that structural stability has a non-monotonic relationship with system connectivity. We also demonstrate that networks with a hierarchical structure are more likely to be stable to perturbations than those with a more entangled heterarchical structure. These results support future work attempting to characterize the scaling relationship between structural stability and system connectivity. The latter investigation is necessary to evaluate several conjectured but ultimately untested hypotheses about biological networks.
\end{abstract}

\maketitle

% \section{Todo}
% \listoftodos

\section{Introduction}

The traditional approach taken in the study of chemical reaction, gene-regulatory, population, and ecosystem networks is to consider a particular example, derive a system of differential equations to model that example, try to fit the model to data and adjust the modeling assumptions along with parameter values until a good fit is achieved. Recent work has demonstrated that as a result of sloppiness in the dependence of qualitative dynamic phenomena on the geometry of parameter space that this approach allows for a large variety of models to ``fit the data'' \cite{Brown2003,Gutenkunst2007,Daniels2008a,Machta2013,Hines2014,Prabakaran2014}. In the face of uncertainty about the structure of such biological networks, to model the components under consideration as randomly interlinked becomes a reasonable approximation. This approach enables one to gain insight into what dynamical phenomena are possible to observe within a given class of dynamical systems, which is necessary to understand in order to determine whether or not a particular dynamical phenomenon should be regarded as unique or generic in the development and investigation of models applied to particular systems \cite{Gunawardena2013,Gunawardena2014}.

Indeed, investigating generic properties of a large class of dynamical systems was the approach taken by May in models of ecosystem dynamics \cite{Gardner1970,May1972}. The class of dynamical systems studied by May is so general that to restrict its applicability to ecosystem dynamics is certainly not necessary and perhaps even inefficient with respect to the goal of understanding how biological networks operate across the various relevant levels of organization. For example, the study of chemical reaction, population, and gene-regulatory networks all utilize essentially equivalent mathematical structure as that discussed by May in the context of ecosystem dynamics \cite{RossCr2003,Alon2006,Palsson2006,HamidBolouri2008,Palsson2011a,Voit2012,Sauro2012}. Developing unified mathematical descriptions of all of these is one of the paramount goals of systems biology. This incredibly generic applicability of gaining a better understanding of the class of models investigated by May demonstrates the unequivocal value of deeper investigation.  However, work attempting to continue the development of the so-called May-Wigner stability theorem revealed that May's conjectured stability criterion was not as easy to demonstrate as was initially believed \cite{Cohen1984,May1972a,Radius2014}.

Here we build on work aimed at investigating the stability of randomly connected dynamical systems to state-based perturbations. We precisely compute the probability of stability as a distribution over system connectivity for all systems containing two interacting components. We then proceed to determine the probability of structural stability over the same domain. We find that while stability to perturbations in the state of this class of dynamical systems is independent of system connectivity, perturbations to the magnitude of connections is correlated with connectivity in a non-linear manner. This work reestablishes and clarifies a thread of research that is extremely important for the continuing development of systems biology.

\section{Stability analysis of biological networks}\label{sec:stabanalbn}
In the construction of a class of potential models for biological systems at any level of the biological hierarchy from metabolic to ecosystem-level networks, it is common to first attempt to define a collection of observable phenomena of interest and determine a domain (such as binary numbers, integers, or real numbers) in which each observable can be quantified. Next, it is necessary to establish the interdependencies among system components. The specific manner in which the components depend upon one another must be clarified, which is often done by determining a particular system of mathematical functions that represents a hypothesis about how the quantified observables evolve in time. To the degree to which there is uncertainty about the interactions among system components, parameters are introduced to broaden the class of models under consideration. Finally, whatever model class remains may be compared to empirical observations to determine how capable the model is of representing the phenomena of interest.

For the case of continuous deterministic observables, the above process can be made more precise by associating a manifold to each observable, a directed graph to the interdependencies, and a vector field satisfying these interdependencies for each observable over the space determined by taking the product of the manifolds associated to the collection of observables \cite{Deville}. For example, if we have two observables $\{x_1,x_2\}$ where the domains in which they are quantified are given by manifolds $\{M_1,M_2\}$ such that $x_1 \in M_1 \equiv \mathbb{R}^1$ and $x_2 \in M_2 \equiv \mathbb{R}^1$, a directed graph $G_X$ describing the dependencies between these observables and vector field $V$ with components $\{F_1,F_2\}$ defined on $M_1 \otimes M_2 \equiv \mathbb{R}^2$ satisfying the dependencies determined by $G_X$. If the system under consideration has the graph shown in \ref{fig:examplesystemmodules}A
% \begin{center}
% \input{tex/examplehamdyngraph}
% \end{center}
with adjacency matrix
$$
\adj(G_X) = \begin{pmatrix}
0 & 1 \\
1 & 1
\end{pmatrix}
$$
then for the system $X = \{G_X, M_X, F_X\}$, where $M_X \equiv \{M_1,M_2\}$ and $F_X \equiv \{F_1,F_2\}$ such that $F_1$ is constrained to be a function of $x_2$ and $F_2$ is a function of both $x_1$ and $x_2$ yielding the flow equations
\begin{align*}
\frac{dx_1}{dt} & = F_1(x_2)\\
\frac{dx_2}{dt} & = F_2(x_1,x_2)
\end{align*}

\begin{figure}[!ht]
\centering
\noindent\includegraphics[width=0.6\columnwidth]{fig/examplesystemmodules.pdf}
\caption{{\bf Example of the combination of open system modules to construct closed systems.} (A) Example of combining two open modules to construct a closed system of two components (B) Analogous example for combining three open modules to construct a closed system with three components}
\label{fig:examplesystemmodules}
\end{figure}

In the more general case of a system with $n$ components we would have an $n$-dimensional vector of observables
$$
x(t) = (x_1(t), \ldots x_n(t)) = \vec{x}(t)
$$
whose components are solutions to the arbitrary first order system
$$
\frac{dx_i(t)}{dt} = F_i(\vec{x}(t)), \; (i=1,\ldots,n)
$$
where $F_i$ represent, potentially nonlinear, functions of the given vector of state variables.

In order to accommodate the possibility of uncertainty in our modelling,
we will generalize our notion of a system on a network to that of a
system with random parameters.  Again, this will involve three
steps. First, we provide a measure space $S$ which represents the
values over which our parameters can vary. Next, instead of a single
vector field, we consider a family of vector fields parameterized by
this space. That is to say, we introduce a mapping $V$ from $S$ to
sections of the tangent bundle of the product of manifolds. As before,
for each point $p \in S$, the vector field $V(p)$ must be consistent with
the system graph. Finally, we select a probability measure $\mu$ on
$S$ which represents our understanding of which values of the parameters
are likely. In accord with Bayesian statistics, we might revise this
distribution as data comes in or use it to estimate parameters and error
bars from experimental results.

Having done this, we are now in a position to do a probabilistic analysis.
Given some quantity $q$ characterizing our system (such as, for instance,
the time it would take a particle to travel between two points), this
quantity now becomes a random variable.  We may then study the average
value, variance, and the like.  Another question one can ask is that of
robustness, which is the conditional probability that, if some property
holds for a set of parameters, it will still hold if we make some random
perturbation about those parameter values.


This description can be formalized as a directed graph $G_X$ that describes the manner in which each of the variables depends upon one another given by an adjacency matrix $\adj(G_X)$ where
 \begin{displaymath}
   \adj(G_X)_{ij} = \left\{
     \begin{array}{ll}
       1, & F_i \hbox{ depends on } x_j\\
       0, & F_i \hbox{ does not depend on } x_j
     \end{array}
   \right.
\end{displaymath}
A graph can be decomposed into a natural collection of \emph{modules} called strongly connected components. A strongly connected component of a graph is a maximal subset of vertices where each vertex within the subset can be reached from any other \cite{Cormen2009}. The strongly connected components of some examples of three component systems are outlined in \ref{fig:scc}.

\begin{figure}[!ht]
\centering
\noindent\includegraphics[width=0.7\columnwidth]{fig/scc.pdf}
\caption{{\bf Example of strongly connected components.} (A) - (D) show strongly connected components highlighted in gray for each of the four graphs representing the interdependencies relevant to four different three component systems. Note that the most hierarchical system in (A) has the highest possible number of connected components, three, whereas the system containing a single cycle and therefore posessing no hierarchy contains only one connected component. Systems (B) and (D) represent examples of hierarchical modular systems that posess both modularity and hierarchy.}
\label{fig:scc}
\end{figure}

Linearization of the $F_i$ about any equilibrium solution $\vec{x}^0$ such that $F_i(\vec{x}^0)=0$ leads to the system
\begin{equation}\label{eq:lineardynsys}
\frac{d\vec{y}(t)}{dt} = A \vec{y}(t),
\end{equation}
where $\vec{y} = \vec{x} - \vec{x}^0$ and the $n \times n$-matrix $A$ has components
$$
a_{ij} = \left. \frac{\partial F_i}{\partial x_j} \right|_{\vec{x} = \vec{x}^0}.
$$
To each dynamical system having Jacobian matrix $A$ at some fixed point $\vec{x}^0$ we can associate a directed graph $G_A$ given by an adjacency matrix $\adj(G_A)$ where
 \begin{displaymath}
   \adj(G_A)_{ij} = \left\{
     \begin{array}{lr}
       1, & a_{ij} \neq 0\\
       0, & a_{ij} = 0
     \end{array}
   \right.
\end{displaymath}
The graphs $G_X$ and $G_A$ are equivalent because the condition $F_i$ independent of $x_j$ definitive of $\adj(G_X)$ corresponds precisely to $\frac{\partial F_i}{\partial x_j}=0$.

The spectral abscissa of the matrix $A$ is defined as
$$
\eta(A) = \max_i \{\Re(\lambda_i)\}
$$
where $\lambda_i$ are the eigenvalues of $A$. The system defined by $F_i$ and $\vec{x}^0$ is dynamically stable if the spectral abscissa of $A$ is less than zero, equivalently, $\eta(A) < 0$. This is because the general solution to \ref{eq:lineardynsys} is
$$
y_i(t) = \sum_j b_{ij} e^{\lambda_j t}, \; (i=1,\ldots,n)
$$
for some matrix $B=(b_{ij})$ and thus all $\vec{y} = \vec{x} - \vec{x}^0$ decay to zero when all $\lambda_i < 0$.

To determine whether a randomly selected dynamical system evaluated at a random critical point, given by a matrix such as $A$, is stable, it is sufficient to check the above condition. Integrating over the region of the parameter space defining $A$ enables the determination of the probability of stability to perturbations in state $\vec{x}$ over an ensemble of dynamical systems.

Another form of stability, referred to as structural stability \cite{Smale1967}, requires the determination of whether or not a given dynamical system that is determined to be stable remains stable under a perturbation to one of its defining parameters. This can be formalized as the conditional probability distribution
$$
P(A' \, \textrm{stable}\, \big| \, A \, \textrm{stable})
$$
where $A'$ represents a matrix derived from some perturbation applied to the matrix $A$ given above. In the simple case where $A \in \mathbb{R}^{n \times n}$ the perturbation which involves sampling uniformly over the $a_{ij}$ defining $A$ the value of a particular $a_{ij}$ from a given probability distribution.

\section{Stability criteria}
Suppose that $M$ is an $n \times n$ matrix with real coefficients.
Motivated by the discussion of \ref{sec:stabanalbn}, we will call
the matrix $M$ stable if all its eigenvalues have negative real part.
Define the characteristic polynomial as $\chi(M)(z) = \det(zI - M)$.
Denote the coefficients of $\chi(M)$ as $s_j$ and its roots as $r_j$,
writing $p(x) = x^n + \sum_{k=1}^n s_k x^{n-k} = \prod_{k=1}^n (x-r_k)$.
Then, since the roots of $\chi$ are the eigenvalues of $M$, asking that
$M$ be stable is equivalent to asking that the roots of $\chi$ all have
negative real part.  We will formulate conditions for this to happen in
terms of the coefficients of $\chi$.

\begin{lemma}
If $M$ is stable, then $s_i > 0$ for all $i$ between $1$ and $n$.
\end{lemma}

\begin{proof}
Assume that $M$ is stable and that it has $2m$ complex roots which come in
complex conjugate pairs and $n-m$ real roots.  Let $r_1 \ldots, r_{2m}$ be
the complex roots with $r_{2k+1}$ being the complex conjugate of $r_{2k}$
and let $r_{2m+1}, \ldots,  r_{n}$ be the real roots. Then we can write the
factorization as follows:
\[
\chi(M)(z) = \prod_{k=1}^{m} (z^2 - (r_{2k} + r_{2k+1}) z + r_{2k} r_{2k+1})
             \prod_{k=2m+1}^{n} (z - r_k)
\]
Since $r_{2k}$ and $r_{2k+1}$ are complex conjugates, $r_{2k} + r_{2k+1} =
\Re r_{2k} = \Re r_{2k+1}$ and $r_{k} r_{2k+1} > 0$.   Since all the
roots have negative real part, all the coefficients of the terms in
the products above are positive so, when we multiply out the product,
we will have all positive terms.  Hence, we conclude that a necessary
condition for $M$ to be stable is that $s_k > 0$ for all $k$.
\end{proof}

To state the next criterion, we will require the quantity $\Delta$, which
is defined as $\prod_{j=1}^{n-1} \prod_{k=j+1}^n (r_1 + r_j)$.  Since
this expression is invariant under permuting the roots, it may be expressed
as a function of the coefficients $s_i$; for small values of $n$, the
resulting expression looks as follows:
\begin{align*}
n=2 \qquad &\Delta = s_1 \\
n=3 \qquad &\Delta = s_3 - s_1 s_2 \\
n=4 \qquad &\Delta = s_1 s_2 s_3 - s_3^2 - s_1^2 s_4 \\
n=5 \qquad &\Delta = s_1 s_2 s_3 s_4 - s_3^2 s_4 - s_1^2 s_4^2 -
                     s_1 s_2^2 s_5 + s_2 s_3 s_5 + 2 s_1 s_4 s_5 - s_5^2
\end{align*}

\begin{lemma}
Given a polynomial $p(z) = z^n + \sum_{k=1}^{n-1} s_k z^{n-k}$ and a real number
$\epsilon > 0$, there exists $\delta \in \mathbb{R}$ such that, if $p'(x) =
x^n + \sum_{k=1}^{n-1} {s'}_i z^i$ is a polynomial for which $|s_i - {s'}_i|
< \delta$ then to every root $r$ of $p$ there corresponds a root $r'$ of
$p'$ such that $|r-r'| < \epsilon$.
\end{lemma}

\begin{proof}
Without loss of generality, we may assume that $\epsilon < 1$.

We first consider the case where $p = x^n$.

If we make the rescaling $x = \epsilon y/2$ in the equation $p(x)  = 0$,
we obtain the equation
\[
y^n + \sum_{k=1}^{n-1} \left(\frac{2}{\epsilon}\right)^k s_k y^{n-k} = 0 .
\]
Cauchy's bound on the roots of this equation is
\[
|y| < 1 + \max_j \left(\frac{2}{\epsilon}\right)^j |s_j| ,
\]
which becomes the bound
\[
|x| < \frac{\epsilon}{2} + \max_j \left(\frac{2}{\epsilon}\right)^{j-1} |s_j|
< \frac{\epsilon}{2} + \left(\frac{2}{\epsilon}\right)^{n-1} \max_j |s_j|
\]
for the original equation.  Hence, if we choose $\delta = (\epsilon/2)^{n}$,
we will have $|x| < \epsilon$.

Next, we generalize to the case $p = (x-r)^n$.

To extend this result of the general case, we note that, given two
polynomials $p = x^m + \sum_{k=1}^n a_k x^{m-k}$ and
$q = x^n + \sum_{k=1}^n b_k x^{n-k}$, the Jacobian of the map which
sends the coefficients of the matrices to the coefficients of the
product $pq$ is the Sylvester matrix, whose determinant is the resultant
of $p$ and $q$.  Hence, is $p$ and $q$ have no common root, the map
is locally invertible.
\end{proof}

\begin{lemma}
If a point lies on the boundary of the set of stable polynomials, then
either $s_n = 0$ and $\Delta = 0$.
\end{lemma}

\begin{proof}
Since the mapping which sends the roots of a polynomial to its
coefficients has non-singular Jacobian when the discriminant is not
zero, if a stable polynomial has distinct roots, it does not lie on
the boundary.

Suppose that we have a family
of polynomials whose roots are of one type but turn into another type.
There are three ways this could happen:
\begin{itemize}
\item{1.} A real root could go from being positive to being negative
  or vice versa.  For this to happen, we must pass through an
  intermediate value with a zero root.  For that intermediate value,
  we have $D = 0$.
\item{2.} A pair of real roots could turn into a pair of complex roots
  or vice versa.  For this to happen, we must pass through an
  intermediate value with a repeated root.  For that intermediate
  value, we have $\delta = 0$.
\item{3.} A conjugate pair of complex roots could go from having
  positive real part to having negative real part or vice versa.  For
  this to happen, we must pass through an intermediate value in which
  the real part is zero.  For that intermediate value, the two roots
  are imaginary so, bing conjugates, they sum to zero, hence we have
  $\Delta = 0$.
\end{itemize}
\noindent  Thus, we conclude that the boundaries of our regions
$R_{abcd}$ consist of portions of the surfaces $D=0, \delta=0,
\Delta=0$ and we will characterize them by studying these surfaces.

To complete the proof, we show that the condition $\delta = 0$ is not
needed to describe the boundary.  Suppose that $\delta = 0$.  Then there
must exist a repeated root.  If the real part of any root, repeated or
not, is positive, then the polynomial is not stable and, by continuity,
if one allows the coefficients to vary within a sufficiently small
ball about that solution, the root will remain negative, so the
polynomial cannot lie on the boundary of the stable region.  If all
the roots, including the repeated ones, are negative then, by a similar
argument the point is in the interior of the stable region.  The only
other possibility is that some root has zero real part, but then
$\Delta = 0$ so the condition $\delta = 0$ is superfluous.
\end{proof}

Introduce $V$ as the parameter space of all polynomials of degree $n$
with real coefficients.  In other words, $V$ is a real vector space of
dimension $n$ whose coordinates we will identify with the coefficients
$s_k$ of our polynomial.  We now partition this space into regions
corresponding to specific types of polynomials.  Let $R_{abcd}$ be the
subset of $V$ such that $x \in R_{abcd}$ if and only if the polynomial
corresponding to $x$ has $a$ positive real roots, $b$ negative real
roots, $c$ complex roots with positive real part and $d$ complex roots
with negative real part.  Once we characterize these regions using
invariants, we will have solved the original problem because a matrix
is stable if the point of $V$ corresponding to it lies in a region of
the form $R_{a0c0}$.

Next, we introduce some products:
\begin{align}
D &= \prod_{k=1}^n r_n \cr
\delta &= \prod_{j=1}^{n-1} \prod_{k=j+1}^n (r_1 - r_j)^2 \cr
\Delta &= \prod_{j=1}^{n-1} \prod_{k=j+1}^n (r_1 + r_j) \cr
\end{align}

Since these quantities are invariant under permutation of the roots
$r_j$, they may be expressed as functions of the coefficients $s_j$.
The explicit expressions may be obtained by such techniques as long
division and determinants. These quantities are of interest because they describe the boundaries between the regions introduced above.

The simplest case is $n=2$.  There we have the regions $R_{2000},
R_{1100}, R_{0200}, R_{0020}, R_{0002}$ and our invariants are $D =
s_2, \delta = s_1^2 - 4s_2, \Delta = s_1$.  The relation between these
is summarized by the conditions
\begin{align}
R_{2000} \qquad &D > 0, \delta > 0, \Delta > 0, \cr
R_{1100} \qquad &D < 0, \delta > 0, \cr
R_{0200} \qquad &D > 0, \delta > 0, \Delta < 0, \cr
R_{0020} \qquad &\delta < 0, \Delta > 0, \cr
R_{0002} \qquad &\delta < 0, \Delta < 0. \cr
\end{align}
These regions used for the classification of stability of two-component systems are show in \ref{fig:region2x2}. The stable regions are given by $R_{2000}$ and $R_{0020}$. All of the other regions represent unstable matrices.

\begin{figure}[!ht]
\centering
\noindent\includegraphics[width=0.5\columnwidth]{fig/region2x2.pdf}
\caption{{\bf Stability conditions on coefficients of the characteristic polynomial for two component systems.} The regions correspond to all possible relationships between the invariants determined by the characteristic polynomial. Colors correspond to the regions given in the main text Green: $R_{2000}$, Red: $R_{1100}$, Yellow: $R_{0200}$, Magenta: $R_{0002}$, Blue: $R_{0020}$.}
\label{fig:region2x2}
\end{figure}

Moving to $n=3$, our invariants now look as follows: $D = s_3, \delta
= 18 s_1 s_2 s_2 + s_1^2 s_2^2 - 4 s_2^3 - 4 s_1^3 s_3 - 27 s_3,
\Delta = s_1 s_2 - s_3$.  However, now we can no longer simply use their
signs to distinguish regions.  For instance, consider the regions
$R_{3000}$ and $R_{1200}$.  These both have $D > 0$ and $\delta > 0$
but to tell them apart, we need to note that the region $\delta > 0$
has two connected components and use the auxiliary condition that $s_1 > 0$ to
specify which of the components contains our region. The regions analogous to \ref{fig:region2x2} for three component systems where $D=1$ is given in \ref{fig:region3x3}.
%(Looking at the sign of $\Delta$ will not help here because, while $\Delta > 0$ in the region $R_{3000}$, it is also positive for some elements of $R_{1200}$ as well.)

\begin{figure}[!ht]
\centering
\noindent\includegraphics[width=0.5\columnwidth]{fig/region3x3.pdf}
\caption{{\bf Stability conditions on coefficients of the characteristic polynomial for three component systems.} Colors correspond to the following regions Green: $R_{3000}$, Red: $R_{1200}$, Yellow: $R_{1002}$, Blue: $R_{1020}$. This is the plane $s_3=1$.}
\label{fig:region3x3}
\end{figure}

\section{System graph and decomposition into strongly connected components}
Next, we will want to relate prpoperties of our matrix and its eigenvalues
to  properties of the associated graph $G_A$.  To do this, we will first
examine the category of paths on $G_A$, and derive a formula expressing
the chararacteristic polynomial as a sum over cycles.

Given a digraph $G$, let $\Path (a,b)$ denote the set of paths from the
vertex $a$ to the vertex $b$.  Given a path $p_1$ from $a$ to $b$ and a path
$p_2$ from $b$ to $c$, we may concatenate them to obtain a path $p_1 \circ
p_2$ from $a$ to $c$.  Hence, $(\Vertex(G), \Path(G), \circ)$ forms a category.


The characteristic polynomial $\chi(A)$ associated to $A$ can be factored according to the strongly connected components of the graph $G$. $$\frac{\chi(M)'(z)}{\chi(M)(z)} = \tr (zI - M)^{-1}$$ where, $\chi(M)(z) = \det (zI - M)$ is the chararacteristic polynomial of the matrix $M$ with $z$ a complex variable.  This formula is readily verified when $M$ is diagonal and has the nice property of being additive over decompositions of the matrix. Making the change of variables $x=\frac{1}{z}$, we have $$\tr (I - xM)^n = \sum_{n=0}^\infty x^n \sum_{a \in \Vertex(G)} \sum_{p \in \Path_n (G)(a,a)} F(p)$$
where $G$ is the graph of the matrix and $\Path_n (G;a,b)$ is the set of
paths of length $n$ from $a$ to $b$.  ; $F$ is the functor from this category to the multiplicative semigroup of the real numbers which corresponds to the matrix $M$.

We now make use of the additivity.  Let $\hier$ be the functor which
sends $G$ to a poset $P$.  Then every element $p$ of $\Path(a,a)$ lies
in $\hier^{-1} (\hier(a))$.  Hence, our sum decomposes into partial sums
for the fibers of the points in the hierarchy which corresponds to a
factorization of the characteristic polynomial.



\section{Two component systems}
For two-component systems having $2 \times 2$ Jacobian matrices, the aforementioned stability criteria result in the conditions $T < 0$ and $D >
0$ where $T$ and $D$ denote the trace and the determinant.

Suppose we have a stable matrix
$$
\begin{pmatrix}
a & b \\
d & c
\end{pmatrix}
$$
where $a + c < 0$ and $ac > bd$. We will consider the case in which each of the parameters defining the matrix is sampled from the uniform distribution $\mathcal{U}(-1,1)$ so that the parameter space corresponds to the $d$-dimensional hypercube, $H^d$, of edge length $r=2$, centered about the origin, and having volume $r^d$.  We want to know the probability that, if we resample an element of this matrix, the result will be stable.  By symmetry, there are two cases to consider; resampling $a$ is equivalent to resampling $c$ and resampling $b$ is equivalent
to resampling $d$.

Suppose that we resample $b$.  We want to compute the probability that a random stable matrix will remain stable upon resampling $b$, which is
% \begin{strip}
\begin{align}\label{eq:condprob}
P\left(\begin{pmatrix}
a & b' \\
d & c
\end{pmatrix} \textrm{stable } \bigg| \begin{pmatrix}
a & b \\
d & c
\end{pmatrix} \textrm{stable } \right)
& = \frac{P\left(\begin{pmatrix}
a & b \\
d & c
\end{pmatrix} \textrm{stable and } \begin{pmatrix}
a & b' \\
d & c
\end{pmatrix} \textrm{stable } \right)}{P\left(\begin{pmatrix}
a & b \\
d & c
\end{pmatrix} \textrm{stable } \right)}.
\end{align}
The denominator of \ref{eq:condprob} is given by
\begin{align*}
P\left(\begin{pmatrix}
a & b \\
d & c
\end{pmatrix} \textrm{stable } \right) = \frac{\int_{\genfrac{}{}{0pt}{}{\genfrac{}{}{0pt}{}{ac>bd}{a+c<0}}{H^4}} da\,db\,dc\,dd\,1}{\int_{H^4} da\,db\,dc\,dd\,1}.
\end{align*}
Since the trace does not involve $b$, the $T<0$ condition will be satisfied automatically and we only need to examine the determinant. Thus, we have the inequalities $ac > b'd$ and $-1 < b' < 1$ in addition to the previous constraints leading to an expression for the numerator of \ref{eq:condprob}
\begin{align*}
P\left(\begin{pmatrix}
a & b \\
d & c
\end{pmatrix} \textrm{stable and } \begin{pmatrix}
a & b' \\
d & c
\end{pmatrix} \textrm{stable } \right) = \frac{\int_{{{ac>b'd \atop ac>bd} \atop a+c<0} \atop H^5} da\,db\,dc\,dd\,db'\,1}{\int_{H^5} da\,db\,dc\,dd\,db'\,1}.
\end{align*}
The analogous equation for resampling $a$ is
\begin{align*}
P\left(\begin{pmatrix}
a & b \\
d & c
\end{pmatrix} \textrm{stable and } \begin{pmatrix}
a' & b \\
d & c
\end{pmatrix} \textrm{stable } \right) = \frac{\int_{{{{a'c>bd \atop a' + c < 0} \atop ac>bd} \atop a+c<0} \atop H^5} da\,db\,dc\,dd\,da'\,1}{\int_{H^5} da\,db\,dc\,dd\,da'\,1}.
\end{align*}

\newcommand{\specialcell}[2][c]{%
  \begin{tabular}[#1]{@{}c@{}}#2\end{tabular}}

\begin{table}[h]
\begin{tabular}{ c || c | c | c }
\hline
matrix & connectivity & \specialcell{probability of stability\\to perturbation} & probability of stability\\
\hline
  $\begin{pmatrix}
a & b \\
d & c
\end{pmatrix}$ & 4 & 0.62 & 0.25 \\
  $\begin{pmatrix}
a & b \\
d & 0
\end{pmatrix}$, $\begin{pmatrix}
0 & b \\
d & c
\end{pmatrix}$ & 3 & 0.5 & 0.25 \\
  $\begin{pmatrix}
a & 0 \\
d & c
\end{pmatrix}$, $\begin{pmatrix}
a & b \\
0 & c
\end{pmatrix}$ & 3 & 0.67 & 0.25 \\
$\begin{pmatrix}
a & 0 \\
0 & c
\end{pmatrix}$ & 2 & 0.5 & 0.25 \\
\end{tabular}
\caption{{\bf Probability of stability under resampling and \emph{a priori} stability for two component systems derived analytically}. All matrices not listed have $0$ probability of stability.}\label{tab:structstabmat}
\end{table}

The probability of \emph{a priori} stability and of stability to perturbations for all two component systems is given in Table \ref{tab:structstabmat}.

\section{Three component systems}

The probability of \emph{a priori} stability and of stability to perturbations for all three component systems is given in Table \ref{tab:structstabmat3}. \ref{fig:connectcycle3D3x3} shows the probability of stability to perturbations for all three component systems as a function of connectivity and number of cycles. \ref{fig:stab3x3} shows the probability of stability to perturbations for all three component systems as a function of connectivity. \ref{fig:cycle3x3} shows the probability of stability to perturbations for all three component systems as a function of the number of simple cycles (elementary circuits) of length greater than one in the corresponding directed graph \cite{Johnson1975}.

\begin{figure}[!ht]
\centering
\noindent\includegraphics[width=0.8\columnwidth]{fig/connectcycle3D3x3.pdf}
\caption{{\bf Plot of stability to perturbations versus number of cycles and connectivity for three component systems.} }
\label{fig:connectcycle3D3x3}
\end{figure}

\begin{figure}[!ht]
\centering
\noindent\includegraphics[width=0.8\columnwidth]{fig/stab3x3.pdf}
\caption{{\bf Plot of stability to perturbations versus connectivity for three component systems.} }
\label{fig:stab3x3}
\end{figure}

\begin{figure}[!ht]
\centering
\noindent\includegraphics[width=0.8\columnwidth]{fig/cycle3x3.pdf}
\caption{{\bf Plot of stability to perturbations versus number of cycles for three component systems.} }
\label{fig:cycle3x3}
\end{figure}

\newpage

\bibliographystyle{amsplain}
\bibliography{bib/books,bib/papers}

\newpage

\input{tex/tablenographs}

\newpage

% \input{tex/tablewithgraphs}

\section{Appendix A}\label{sec:appA}


\end{document}

%------------------------------------------------------------------------------
% End of journal.tex
%------------------------------------------------------------------------------
